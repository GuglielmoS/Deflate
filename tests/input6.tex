\documentclass[11pt]{article}

% per utilizzare gli accenti
\usepackage[applemac]{inputenc}

% per utilizzare le immagini
\usepackage{graphicx}

% senza questo da alcuni problema sulla formattazione delle formule
\usepackage{amsmath}

% simboli insieme numerici
\usepackage{amssymb}

% impostazioni foglio
\usepackage[a4paper,top=1.5cm,bottom=1.5cm,left=2cm,right=2cm]{geometry}

% percorso cartella immagini
\graphicspath{{images/}}

% prima pagina

\title{\textbf{Formulario - Algebra Lineare II}}
\author{\textit{Guglielmo Fachini}}
\date{\textit{\today{}}}

\begin{document}

\maketitle

\section{Autovalori e autovettori}
Data $f: \mathbb{V}^n \rightarrow \mathbb{V}^n$, se $\vec x \in \mathbb{V}^n, \vec x \ne \vec 0$ allora:
\newline
$$ \vec y = F \vec x = \lambda \vec x, \lambda \in \mathbb{R} $$
Si dice quindi che $\vec x$ è un \textit{autovettore} per $F$ relativo all'\textit{autovalore} $\lambda$.  

\subsection{Calcolo di autovalori}
Gli autovalori vengono trovati ponendo uguale a zero il polinomio caratteristico $P_A(\lambda$)
\begin{equation}
P_A(\lambda) = det(A - \lambda I)
\end{equation}
\subsubsection{Proprietà}
\begin{itemize}
\item{gli autovalori di una matrice triangolare o diagonale coincidono con gli elementi sulla diagonale della matrice stessa}
\item{una matrice di dimensione $n$ x $n$, possiede sempre $n$ autovalori (reali o complessi)}
\item{l'insieme di tutti gli autovalori viene detto spettro e si indica con $S_A$}
\item{la molteplicità algebrica di un autovalore indica quante volte questo si ripete nello spettro}
\item{la somma delle molteplicità algebriche degli autovalori di una matrice $n$ x $n$ è uguale ad $n$}
\item{le matrici simmetriche possiedono tutti autovalori reali}
\end{itemize}

\section{Autospazi}
Data una matrice quadrata $A$ e un autovalore $\lambda$ di A, l'autospazio relativo a $\lambda$, indicato con
 $E_{\lambda}$, è formato da tutti gli autovettori relativi a $\lambda$ e dal vettore nullo. Si può verificare che gli
 autospazi sono spazi vettoriali.
 
 \subsection{Calcolo di autospazi}
Il calcolo dell'autospazio $E_\lambda$ relativo all'autovalore
 $\lambda$ si effettua risolvendo il sistema omogeneo:
 \begin{equation}
 (A - \lambda I)\vec x = \vec 0 
 \end{equation}

\subsubsection{Proprietà}
\begin{itemize}
\item{la molteplicità geometrica di un autovalore $\lambda$, è pari al numero di vettori linearmente indipendenti
	che generano l'autospazio $E_\lambda$, ed è sempre minore o uguale alla molteplicità algebrica di $\lambda$}
\item{autovettori relativi ad autovalori diversi di una stessa matrice, sono tra loro linearmente indipendenti}
\item{l'autospazio $E_0$ corrisponde a $ker(A)$, perciò se $m.a.(0) = 1$ ho che $rang(A) = n - 1$}
\end{itemize}

\newpage

\section{Autovalori ed autospazi di $A^{-1}$ e $A^n \; (n \in \mathbb{N)}$}
Sia $A_n$ con $S_A = \left\{ \lambda_1, \dots, \lambda_n \right\}$
\begin{enumerate}
\item{Se $\lambda_i \ne 0 ,\; \forall i \in \left\{1, \dots, n\right\}$ allora $\exists A^{-1} $ con 
	$S_A = \left\{ \frac{1}{\lambda_1}, \frac{1}{\lambda_2}, \dots, \frac{1}{\lambda_n} \right\} $}
\item{Per $A^m \; (m \in \mathbb{N})$ si ha $S_A = \left\{ \lambda_1^m, \lambda_2^m, \dots, \lambda_n^m \right\} $}
\end{enumerate}
Gli autospazi $E_{\lambda_i}$ rimangono invariati in tutti e due i casi.

\section{Matrici simili}
Due matrici $A_n$ e $B_n$ si dicono simili se esiste una matrice di passaggio $C_n$ non singolare ($\exists C_n^{-1}$) tale che:
$$ A = C B C^{-1} \Rightarrow B = C^{-1} A C $$
\subsection{Proprietà}
\begin{enumerate}
\item{$det(A) = det(B)$ \hfill (stesso determinante)}
\item{$tr(A) = tr(B)$ \hfill (stessa traccia)}
\item{$S_A = S_B$ \hfill (stessi autovalori)}
\item{Se $\vec x_i$ è un autovettore per $A$ relativo all'autovalore $\lambda_i$, allora $\vec y_i = C^{-1} \vec x_i$ è
	un autovettore per $B$ relativo all'autovalore $\lambda_i$}
\end{enumerate}

\section{Diagonalizzazione}
\`E un processo matematico attraverso il quale a partire da una matrice quadrata si ricava un matrice simile diagonale,
che ha gli autovalori della matrice di partenza sulla diagonale.
\newline
La condizione per cui una matrice può essere diagonalizzata è che la molteplicità algebrica sia uguale alla molteplicità geometrica per ogni autovalore:
$$ m.a.(\lambda_i) = m.g.(\lambda_i) $$
In questo modo, data una matrice quadrata $A$ che soddisfa questa condizione, possiamo dire che:
\begin{equation}
A = S \Lambda S^{-1}
\end{equation}
Dove $S$ è composta dagli autovettori di $A$, mentre $\Lambda$ è una matrice diagonale che ha per valori sulla diagonale gli autovalori di $A$.
\newline
Ad esempio:
$$ S_A = \left\{1,2\right\} , \; E_1 = \, <\left(\begin{array}{c}1 \\1\end{array}\right)> , \; E_2 = \, <\left(\begin{array}{c}0 \\1\end{array}\right)> $$
$$ \Rightarrow A = \left(\begin{array}{cc}1 & 0 \\1 & 1\end{array}\right) \left(\begin{array}{cc}1 & 0\\0 & 2\end{array}\right)
\left(\begin{array}{cc}1 & 0 \\1 & 1\end{array}\right)^{-1}  $$

\newpage

\section{Matrici simmetriche}
Sia $A_n$ una matrice simmetrica reale $(a_{ij} = a_{ji} , \; A^T = A, \; a_{ij} \in \mathbb{R})$ :
\begin{enumerate}
\item{tutti gli autovalori di $A$ sono reali \hfill $(\lambda_i \in \mathbb{R})$}
\item{$A$ è sempre diagonalizzabile \hfill $(m.a.(\lambda_i) = m.g.(\lambda_i), \: \forall \lambda_i)$}
\item{autovalori relativi ad autovettori distinti sono ortogonali \hfill (\textit{dot product} = 0)}
\item{a partire da $S$ si può costruire una matrice ortogonale $O$ che ha le colonne che sono ortogonali a due a due
	e di norma unitaria; inoltre $O^{-1} = O^T$. Per ottenere $O$ si costruiscono i versori degli autovettori.}
\end{enumerate}

\section{Teorema di Cayley-Hamilton}
Sia $A_n$ una matrice quadrata, allora $P_A(A)$ è un polinomio matriciale in $A$ di grado $n$.
\newline
Infatti conoscendo il polinomio caratteristico di $A$ ($P_A(\lambda)$), possiamo sostiuire $A$ al posto di $\lambda$,
andando così a creare questa condizione: 
\begin{equation}
P_A(A) = det(A - A I) = 0
\end{equation}
Da qui siamo quindi in grado di esprimere $A^n$, $A^{n+1}$, $A^{n+2}$ come combinazione lineare di $A^{n-1}$, $A^{n-2}$,
$\dots$, $A^2$, $A$, $I$.
\newline
Ad esempio:
$$ A = \left(\begin{array}{cc} -1 & 2 \\1 & -1\end{array}\right) $$
$$ P_A(\lambda) = det(A - \lambda I ) = \lambda^2 + 2 \lambda - 1$$
$$ P_A(A) = 0 \Rightarrow A^2 = -2 A + I $$
Ora posso scrivere $A^k$ come:
$$ A^k = A A^{k-1} $$

\section{Regola del determinante e della traccia}
Data una matrice $A$ di dimensione $n$ x $n$ e i suoi autovalori $\lambda_1,...,\lambda_n$, si ha che:
\begin{equation}
det(A) = \lambda_1 \cdot ... \cdot \lambda_n
\end{equation}
\begin{equation}
tr(A) = \lambda_1 + \dots + \lambda_n
\end{equation}
\subsubsection{Proprietà}
\begin{itemize}
\item{una matrice che possiede almeno un autovalore zero ha sicuramente determinante zero, perciò non
	è invertibile. Viceversa una matrice invertibile ha sicuramente gli autovalori diversi da 0}
\item{la traccia di una matrice reale è un numero reale, quindi la somma delle parti immaginarie di eventuali 
	autovalori complessi deve annullarsi}
\end{itemize}

\section{Calcolo di $e^A$ e $A^k$}
Data una matrice quadrata $A$ diagonalizzabile, posso calcolare $e^A$ ed $A^k$ come:
\begin{equation}
A^k = S \Lambda^k S^{-1}
\end{equation}
\begin{equation}
e^A = S e^\Lambda S^{-1}
\end{equation}

\newpage

\section{Autovalori e autovettori relativi a trasformazioni geometriche}
Quando si sta lavorando con delle trasformazioni geometriche è utile vedere come si comportano gli autovalori e
gli autospazi della rispettiva applicazione lineare.
\newline
\subsection{Proiezione ortogonale su un piano $\alpha$ passante per l'origine}
Per ogni vettore parallelo al piano $\alpha$, ho che dopo la propriezione rimarrà invariato. Perciò questo
mi indica che avrò un autospazio $E_1$ di due dimensioni che equivarrà ad $\alpha$, e il cui relativo autovalore
sarà 1. Dopo di che, sapendo che i vettori perpendicolari al piano finiranno nell'origine, posso anche stabilire che
esiste l'autospazio $E_0 = ker(P) = \left<\vec n_\alpha\right> $ il cui autovalore è 0.
\newline
Si avrà quindi: $S_P = \left\{0, 1, 1\right\} , \; det(P) = 0 , \; tr(P) = 2 $

\subsection{Omotetia in $\mathbb{R}^3$}
$$S_\Omega = \left\{k, k, k\right\} , \; E_k  = \mathbb{R}^3 $$

\subsection{Simmetria in $\mathbb{R}^3$, rispetto una retta passante per l'origine, con una rotazione di $\pi$}
$ S_S = \left\{-1, -1, 1\right\} , \; E_1 = $asse$ , \; E_{-1} = $ piano passante per 0 e $ \bot $ asse

\end{document}
